#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu May 29 16:13:21 2025

@author: ubuntu
"""

import numpy as np
from tqdm import tqdm
import os
import pandas as pd
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
from load_mat_data import load_mat_data
from plot_confusion_matrix_new import plot_confusion_matrix
import pickle
from Repeat_k_fold_cv import Repeat_k_fold_cv
from plot_multiclass_roc_curve import plot_multiclass_roc_curve

# ===== Configuration =====
matfile_path = "fmri_data.mat"  # fMRI feature matrix
pattern = load_mat_data('pattern.mat', 'pattern_key')  # Activation pattern
percentiles = [0,10,20,30,40,50,60,70,80,90,95,96,97,98,99]  # Activation thresholds
output_basepath = "results"  # Output directory

# Load fMRI data matrix
feature_matrix_orig = load_mat_data(matfile_path, 'data_matrix')

# Experimental design parameters
subjects = list(range(561))  # Subject IDs (561 total)
labels = np.array([1]*20 + [2]*20 + [3]*20 + [4]*20)  # Class labels (4 categories × 20 samples)

# Initialize linear SVM classifier
svm = SVC(kernel='linear', probability=True)

# ===== Main Analysis Loop =====
for percentile in percentiles: 
    # Calculate activation thresholds
    threshold_pos = np.percentile(pattern, percentile)
    
    # Select top activated voxels
    selected_features_index = (pattern[:, 0] >= threshold_pos)
    
    # Create output directory
    output_path = os.path.join(output_basepath, f"Top_{100-percentile}")
    os.makedirs(output_path, exist_ok=True)
    
    # Apply voxel selection
    feature_matrix = feature_matrix_orig[:, selected_features_index]
    
    # Initialize result containers
    result_containers = {
        'y_true': [], 'y_pred': [], 'y_score': [],
        'y_true_binarized': [], 'mean_acc': [], 'std_acc': []
    }
    
    # Process each subject
    for subj_idx in tqdm(range(len(subjects)), desc=f"Top {percentile}%"):
        # Extract subject data (80 samples/subject)
        subject_data = feature_matrix[subj_idx*80:subj_idx*80+80, :]
        
        # Run repeated k-fold CV (100 repeats × 10 folds)
        results = Repeat_k_fold_cv(subject_data, labels, model=svm, 
                                  repeat_times=100, n_jobs=10)
        
        # Store results
        for key in result_containers:
            result_containers[key].append(results[key])
    
    # Aggregate results across subjects
    y_pred = np.hstack(result_containers['y_pred'])
    y_true = np.hstack(result_containers['y_true'])
    y_test_binarized = np.vstack(result_containers['y_true_binarized'])
    y_score = np.vstack(result_containers['y_score'])
    
    # Calculate performance metrics
    conf_matrix = confusion_matrix(y_true, y_pred)
    accuracy = accuracy_score(y_true, y_pred)
    mean_accuracy = np.mean(result_containers['mean_acc'])
    std_accuracy = np.mean(result_containers['std_acc'])
    
    # Compute ROC metrics
    roc_aucs = []
    for i in range(y_test_binarized.shape[1]):
        fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score[:, i])
        roc_aucs.append(auc(fpr, tpr))
    
    # Save summary results
    final_results = pd.DataFrame({
        'Mean Accuracy': mean_accuracy,
        'Std Accuracy': std_accuracy,
        'Mean AUC': np.mean(roc_aucs)
    }, index=[0])
    final_results.to_csv(os.path.join(output_path, 'summary.csv'))
    
    # Visualize results
    class_names = ['Body', 'Face', 'Place', 'Tool']
    colors = ['#FFBC00','#92D050','#A076A1','#F58A83']
    
    # Plot ROC curve
    plot_multiclass_roc_curve(y_test_binarized, y_score, class_names, colors,
                             save_filename=os.path.join(output_path, f'roc_curve_{percentile}.png'))
    
    # Plot confusion matrix (percentage format)
    conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100
    plot_confusion_matrix(conf_matrix_percent,
                         savefile_name=os.path.join(output_path, f'confusion_matrix_{percentile}.png'),
                         class_labels=class_names)
    
    # Save detailed results
    save_results = {
        "PerformanceMetrics": {
            "MeanAccuracy": mean_accuracy,
            "StdAccuracy": std_accuracy,
            "ROC_AUCs": roc_aucs
        },
        "Predictions": {
            "TrueLabels": y_true,
            "PredictedLabels": y_pred,
            "Probabilities": y_score
        },
        "ConfusionMatrix": {
            "Counts": conf_matrix,
            "Percentages": conf_matrix_percent
        }
    }
    with open(os.path.join(output_path, "full_results.pkl"), "wb") as f:
        pickle.dump(save_results, f)
    


    

    
